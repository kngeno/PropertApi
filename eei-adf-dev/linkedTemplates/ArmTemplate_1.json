{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "eei-adf-dev"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/buildings_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Clean Buildings CSV to Parquet",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "BuildingsCSV",
								"type": "DatasetReference"
							},
							"name": "buildingsSource"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "BuildingsPq",
								"type": "DatasetReference"
							},
							"name": "buildingsSink"
						}
					],
					"transformations": [
						{
							"name": "derivedColumns"
						}
					],
					"scriptLines": [
						"source(output(",
						"          building_id as string,",
						"          parcel_id as string,",
						"          use_type as string,",
						"          year_built as string,",
						"          floors as string,",
						"          height_m as string,",
						"          construction_status as string,",
						"          permit_number as string,",
						"          regulatory_status as string,",
						"          valuation_amount as string,",
						"          owner_name as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> buildingsSource",
						"buildingsSource derive(year_built = toInteger(year_built),",
						"          floors = toInteger(floors),",
						"          height_m = toDouble(height_m),",
						"          valuation_amount = toDecimal(valuation_amount,18,2),",
						"          construction_status = upper(trim(construction_status)),",
						"          regulatory_status = upper(trim(regulatory_status)),",
						"          use_type = upper(trim(use_type))) ~> derivedColumns",
						"derivedColumns sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          building_id as string,",
						"          parcel_id as string,",
						"          use_type as string,",
						"          year_built as double,",
						"          floors as double,",
						"          height_m as double,",
						"          construction_status as string,",
						"          permit_number as string,",
						"          regulatory_status as string,",
						"          valuation_amount as double,",
						"          owner_name as string",
						"     ),",
						"     format: 'parquet',",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: []) ~> buildingsSink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/companies_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "companies_dataflow",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "CompaniesXLSX",
								"type": "DatasetReference"
							},
							"name": "companiesSource"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "CompaniesPq",
								"type": "DatasetReference"
							},
							"name": "companiesSink",
							"rejectedDataLinkedService": {
								"referenceName": "EEIADF",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "companiesFilterStatus"
						}
					],
					"scriptLines": [
						"source(output(",
						"          company_id as string,",
						"          company_name as string,",
						"          registration_number as string,",
						"          industry as string,",
						"          address as string,",
						"          board_members as string,",
						"          ownership_share as string,",
						"          status as string,",
						"          last_updated as date 'yyyy-MM-dd'",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> companiesSource",
						"companiesSource filter(status == 'Active') ~> companiesFilterStatus",
						"companiesFilterStatus sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          company_id as string,",
						"          company_name as string,",
						"          registration_number as string,",
						"          industry as string,",
						"          address as string,",
						"          board_members as string,",
						"          ownership_share as string,",
						"          status as string,",
						"          last_updated as date",
						"     ),",
						"     format: 'parquet',",
						"     truncate: true,",
						"     umask: 0766,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          company_id,",
						"          company_name,",
						"          registration_number,",
						"          industry,",
						"          address,",
						"          board_members,",
						"          ownership_share,",
						"          status,",
						"          last_updated",
						"     )) ~> companiesSink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/parcels_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Clean and write parcels data",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ParcelsJSON",
								"type": "DatasetReference"
							},
							"name": "parcelsSource"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ParcelsPq",
								"type": "DatasetReference"
							},
							"name": "parcelsSink"
						}
					],
					"transformations": [
						{
							"name": "deriveColumns"
						}
					],
					"scriptLines": [
						"source(output(",
						"          parcel_id as string,",
						"          owner_id as string,",
						"          owner_name as string,",
						"          area_name as string,",
						"          zoning_code as string,",
						"          cadastral_code as string,",
						"          intended_use as string,",
						"          regulatory_status as string,",
						"          land_use as string,",
						"          area_sq_m as double,",
						"          centroid_lon as double,",
						"          centroid_lat as double,",
						"          last_transaction_date as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     documentForm: 'arrayOfDocuments') ~> parcelsSource",
						"parcelsSource derive(last_transaction_date = toTimestamp(last_transaction_date,'yyyy-MM-dd')) ~> deriveColumns",
						"deriveColumns sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          parcel_id as string,",
						"          owner_id as string,",
						"          owner_name as string,",
						"          area_name as string,",
						"          zoning_code as string,",
						"          cadastral_code as string,",
						"          intended_use as string,",
						"          regulatory_status as string,",
						"          land_use as string,",
						"          area_sq_m as double,",
						"          centroid_lon as double,",
						"          centroid_lat as double,",
						"          last_transaction_date as date",
						"     ),",
						"     format: 'parquet',",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> parcelsSink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/people_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Clean People XML to Parquet",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "PeopleXML",
								"type": "DatasetReference"
							},
							"name": "peopleSource"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "PeoplePq",
								"type": "DatasetReference"
							},
							"name": "peopleSink"
						}
					],
					"transformations": [
						{
							"name": "derivedColumns"
						},
						{
							"name": "assertPersonID"
						}
					],
					"scriptLines": [
						"source(output(",
						"          person_id as string,",
						"          full_name as string,",
						"          national_id as string,",
						"          dob as string,",
						"          role as string,",
						"          associated_company as string,",
						"          associated_parcels as string,",
						"          contact_email as string,",
						"          watchlist_status as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     validationMode: 'none',",
						"     namespaces: true) ~> peopleSource",
						"peopleSource derive(dob = toTimestamp(dob,'yyyy-MM-dd'),",
						"          role = upper(trim(role)),",
						"          watchlist_status = upper(trim(watchlist_status)),",
						"          full_name = trim(full_name),",
						"          contact_email = lower(trim(contact_email))) ~> derivedColumns",
						"derivedColumns assert(expectTrue(!isNull(person_id), false, 'assertPersonID')) ~> assertPersonID",
						"assertPersonID sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          person_id as string,",
						"          full_name as string,",
						"          national_id as string,",
						"          dob as date,",
						"          role as string,",
						"          associated_company as string,",
						"          associated_parcels as string,",
						"          contact_email as string,",
						"          watchlist_status as string",
						"     ),",
						"     format: 'parquet',",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: []) ~> peopleSink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pl_clean_and_enrich')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "pl_clean_and_enrich datasets",
				"activities": [
					{
						"name": "CompaniesDataFlowPipeline",
						"description": "CompaniesDataFlowPipeline",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "companies_dataflow",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"companiesSource": {},
									"companiesSink": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"pCleanRoot": {
						"type": "string",
						"defaultValue": "clean"
					},
					"pCuratedRoot": {
						"type": "string",
						"defaultValue": "curated"
					},
					"pIngestDate": {
						"type": "string",
						"defaultValue": "@formatDateTime(utcNow(),'yyyy/MM/dd')"
					}
				},
				"annotations": [],
				"lastPublishTime": "2025-08-25T01:00:23Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/companies_dataflow')]"
			]
		}
	]
}